zookeeper 跨表级事务
	1.投票器
	2.协同
	3.分布式锁
online hbase 半实时（1.集群足够大，2.rowkey毫秒级百亿数据）
	=> 替代1.redis(消息队列) 
	=> 替代2.cassandra+kylin（复制翻译查询语句）
	=> kudu+impall 
	=> 
mapreduce	1.sql03标准
		2.
		弄清流程，优化

流式计算		1.storm（开销）
		2.flink（性能）
		3.sparkstream

spark		1.0 2.0 2.3之后（之后开始支持gpu）
		可以做 mr 可以做的所有事情

Tez		

Hive		底层翻译为 mr（要了解语义分析）

Mahout		、（淘汰但可以参考实现）

flume		kafka

scoop		将各种数据库进行转换

hadoop		2.x 上限集群 1700+
		3.x 10w+
		默认3个副本，没有本的概念（3个），尝试4次都失败才算一个任务失败
			热点数据（增加副本）
			历史数据、没有性能维持（减少副本）

三个月更换
ai: i7-8 / i9,32GB, GPU:1080Ti
课程:i7-6,8GB

3.0开始，hadoop 开始底层支持更新操作

1.数据倾斜	描述：	不同机器存储率差异高
		危害：	效率低
			机器容易坏
		引起描述：研发人员造成，研发30%责任，运维70%责任
		解决	start-balancer.sh 20 起止时间
			20 表示各个机器的数据最大差异是 20%
			问题	可能没有执行平衡，因为对比是否平衡是随机的
			问题	内部会现在网络以保持对外服务依旧可行，需要修改网络限制

2.高低配		一般指不同cpu和内存配置的电脑
		不可行
		1.高配参与计算，低配只能进行存储
		2.计算可能会被拖慢
		一定做，可以将高配虚拟化为多个低配
		一定做，低配可以改成测试用

3.同配不同存	一般描述，同cpu和内存，硬盘容量不同
		会导致当一个机器存满时，另一个机器还有存储空间时，无法继续上传文件

4.虚拟化		内存不能造假，因为一般禁用了 交换空间

5.磁阵		不做

6.拔插		1.本身硬件支持
		2.数据坏损非系统盘坏损
		可以直接拔插换新，因为dn可以自动备存
		直接+插，挂载，之后需要 hadoop namenode format 加入到

调度器
	1.算法
	2.谁可以使用
	3.任务等级(5级)
	4.调度器分多少资源

数据量变大的检索解决方案：	1.建立索引（内存，建立二叉树（可变的）LSM）
			2.rouket=>id

HBAS	1.x 列簇只能最多3个

一个 region 对应一个 storefile 对应多个  hfile => 存储在 hdfs 上???
region 分裂时，hfile随着分裂 --> 做 region 预分区

线上的 hbas 不能执行 mr

hadoop 内部技术

Hadoop 权威指南：大数据的存储与分析（第四版）
hadoop 内部技术:深入解析mr架构技术。。。
hive编程指南
hbas权威指南（十二五国家重点图书出版规划项目）
机器学习（西瓜封面）

thume（数据过滤）+kafka
		->spark(可以加sparkSteam)->sql/ai
		->(存储)	1.db(关系型数据库)(千万集以下)
			2.本地()
			3.hdfs
			4.hive
			5.hbase
			6.redis
			7.mppDB
			8.Cassamdra
			9.Kudu
			10.presto （PB/TB级数据库）
			11.kafka
			12.es	结构化的数据选es，非结构化选solr
			13.solr	
=>(storm/flink/sparkstream)

rdd 弹性数据分布集	

kafka	一般使用2个至多3个副本
	当一个宕机后 1.有投票器 2.记录偏移 进行恢复
		两个记录到 zk 中，zk 压力最大需要最高的配置
	v3.3 起，直接模式	1.partition 不进行处理
